{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ef1db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from dataset_PA1.dataloader import Dataloader\n",
    "from dataset_PA1.dataloader import datasetIterator\n",
    "from CNN_classes_2 import Conv2D\n",
    "from CNN_classes_2 import ReLU\n",
    "from CNN_classes_2 import MaxPool2D\n",
    "from CNN_classes_2 import Flatten\n",
    "from CNN_classes_2 import Linear\n",
    "from CNN_classes_2 import SoftmaxCrossEntropy\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06070261",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = Conv2D(1, 8, 3, lr=0.01)\n",
    "relu1 = ReLU()\n",
    "pool1 = MaxPool2D()\n",
    "conv2 = Conv2D(8, 16, 4, lr=0.01)\n",
    "relu2 = ReLU()\n",
    "pool2 = MaxPool2D()\n",
    "flatten = Flatten()\n",
    "fc = Linear(16 * 5 * 5, 10, lr=0.01)\n",
    "criterion = SoftmaxCrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f667992",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './dataset_PA1'\n",
    "learning_rate = 0.01\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "train_loader = Dataloader(path=data_path, is_train=True, batch_size=batch_size)\n",
    "test_loader = Dataloader(path=data_path, is_train=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a949f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 started.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_loader.images\n",
    "y_train = train_loader.labels\n",
    "x_test = test_loader.images\n",
    "y_test = test_loader.labels\n",
    "\n",
    "y_test_label = np.argmax(y_test, axis=1)\n",
    "\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_acc_history = []\n",
    "\n",
    "def forward_pass(x):\n",
    "    out = conv1.forward(x)\n",
    "    out = relu1.forward(out)\n",
    "    out = pool1.forward(out)\n",
    "    out = conv2.forward(out)\n",
    "    out = relu2.forward(out)\n",
    "    out = pool2.forward(out)\n",
    "    out = flatten.forward(out)\n",
    "    out = fc.forward(out)\n",
    "    return out\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    perm = np.random.permutation(len(x_train))\n",
    "    x_train, y_train = x_train[perm], y_train[perm]\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    n_batches = len(x_train) // batch_size\n",
    "    time_start = time.time()\n",
    "    print(f\"Epoch {epoch+1}/{epochs} started.\")\n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "        xb = x_train[i:i+batch_size]\n",
    "        yb = y_train[i:i+batch_size]\n",
    "\n",
    "        # forward\n",
    "        out = forward_pass(xb)\n",
    "        loss = criterion.forward(out, yb)\n",
    "\n",
    "        preds = np.argmax(out, axis=1)\n",
    "        labels = np.argmax(yb, axis=1)\n",
    "        correct += np.sum(preds == labels)\n",
    "        total_loss += loss\n",
    "\n",
    "        # backward\n",
    "        d_out = criterion.backward()\n",
    "        d_out = fc.backward(d_out)\n",
    "        d_out = flatten.backward(d_out)\n",
    "        d_out = pool2.backward(d_out)\n",
    "        d_out = relu2.backward(d_out)\n",
    "        d_out = conv2.backward(d_out)\n",
    "        d_out = pool1.backward(d_out)\n",
    "        d_out = relu1.backward(d_out)\n",
    "        _ = conv1.backward(d_out)\n",
    "\n",
    "    train_acc = correct / len(x_train)\n",
    "    avg_loss = total_loss / n_batches\n",
    "    train_loss_history.append(avg_loss)\n",
    "    train_acc_history.append(train_acc)\n",
    "\n",
    "    # --- 테스트셋 평가 ---\n",
    "    test_preds = []\n",
    "    test_preds = []\n",
    "    for j in range(0, len(x_test), batch_size):\n",
    "        xt = x_test[j:j+batch_size]\n",
    "        logits = forward_pass(xt)\n",
    "        exp_scores = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "        test_preds.append(np.argmax(probs, axis=1))\n",
    "    test_preds = np.concatenate(test_preds)\n",
    "    test_acc = np.mean(test_preds == y_test_label)\n",
    "    test_acc_history.append(test_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f} | Time: {time.time()-time_start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcff12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = np.arange(1, epochs + 1)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(8,5))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Loss curve\n",
    "ax1.plot(epochs_range, train_loss_history, 'o-', color='tab:red', label='Train Loss')\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\", color='tab:red')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "ax1.grid(True, linestyle='--', alpha=0.4)\n",
    "\n",
    "# Accuracy curve\n",
    "ax2.plot(epochs_range, train_acc_history, 's--', color='tab:blue', label='Train Acc')\n",
    "ax2.plot(epochs_range, test_acc_history, 'd-', color='tab:green', label='Test Acc')\n",
    "ax2.set_ylabel(\"Accuracy\", color='tab:blue')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Combined legend\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='center right')\n",
    "\n",
    "plt.title(\"Training Loss & Accuracy Curve\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_curve.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a224317",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "cm = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "for t, p in zip(y_test_label, test_preds):\n",
    "    cm[t, p] += 1\n",
    "\n",
    "# --- 시각화 ---\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "im = ax.imshow(cm, cmap='Blues')\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"Predicted Label\")\n",
    "ax.set_ylabel(\"True Label\")\n",
    "ax.set_title(\"Confusion Matrix (Test Set)\")\n",
    "ax.set_xticks(range(num_classes))\n",
    "ax.set_yticks(range(num_classes))\n",
    "ax.set_xticklabels(range(num_classes))\n",
    "ax.set_yticklabels(range(num_classes))\n",
    "\n",
    "# 각 칸에 숫자 표시\n",
    "for i in range(num_classes):\n",
    "    for j in range(num_classes):\n",
    "        text_color = \"white\" if cm[i, j] > cm.max() * 0.5 else \"black\"\n",
    "        ax.text(j, i, str(cm[i, j]), ha='center', va='center', color=text_color, fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix_numpy.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a2329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "top_k = 3\n",
    "\n",
    "# 테스트셋 다시 forward (softmax 확률 포함)\n",
    "test_probs = []\n",
    "test_labels = []\n",
    "for j in range(0, len(x_test), batch_size):\n",
    "    xt = x_test[j:j+batch_size]\n",
    "    out = forward_pass(xt)  # softmax까지 포함된 확률\n",
    "    test_probs.append(out)\n",
    "test_probs = np.concatenate(test_probs, axis=0)\n",
    "\n",
    "# 각 클래스별 top3 index 추출\n",
    "top_images = []  # [(img, pred, prob), ...]\n",
    "for c in range(num_classes):\n",
    "    # class c에 대해 예측 확률의 c번째 column을 가져오기\n",
    "    class_confidences = test_probs[:, c]\n",
    "    top_indices = np.argsort(class_confidences)[-top_k:][::-1]\n",
    "    for idx in top_indices:\n",
    "        top_images.append((x_test[idx, 0], np.argmax(test_probs[idx]), class_confidences[idx]))\n",
    "\n",
    "# --- 시각화 ---\n",
    "fig, axes = plt.subplots(num_classes, top_k, figsize=(6, 10))\n",
    "fig.suptitle(\"Top-3 Confident Predictions per Class\", fontsize=14)\n",
    "\n",
    "for c in range(num_classes):\n",
    "    class_confidences = test_probs[:, c]\n",
    "    top_indices = np.argsort(class_confidences)[-top_k:][::-1]\n",
    "    for k, idx in enumerate(top_indices):\n",
    "        ax = axes[c, k]\n",
    "        ax.imshow(x_test[idx, 0], cmap='gray')\n",
    "        ax.axis('off')\n",
    "        pred_label = np.argmax(test_probs[idx])\n",
    "        prob = test_probs[idx, pred_label]\n",
    "        ax.set_title(f\"P:{pred_label} ({prob*100:.1f}%)\", fontsize=7)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.savefig(\"top3_predictions.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
